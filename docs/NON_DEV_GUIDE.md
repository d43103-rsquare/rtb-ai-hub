# RTB AI Hub - 개발 프로세스 혁신 가이드

> 이 문서는 비개발자를 위해 작성되었습니다.
> RTB AI Hub가 무엇이고, 개발 프로세스를 어떻게 바꾸는지, 어떤 방향으로 나아가는지를 설명합니다.

---

## 1. 한 줄 요약

**RTB AI Hub는 디자인부터 배포까지, 개발팀의 반복 업무를 AI가 대신 처리해주는 자동화 시스템입니다.**

---

## 2. 왜 만들었나?

소프트웨어 개발에는 "가치를 만드는 일"과 "반복적인 허드렛일"이 있습니다.

| 가치를 만드는 일 | 반복적인 허드렛일                    |
| ---------------- | ------------------------------------ |
| 아키텍처 설계    | 디자인 보고 Jira 티켓 수십 개 만들기 |
| 핵심 로직 구현   | PR 코드 한 줄 한 줄 리뷰하기         |
| 사용자 경험 개선 | 장애 알림 보고 Jira 티켓 만들기      |
| 기술 의사결정    | 배포 후 모니터링 체크리스트 작성     |

개발자들은 하루 업무 시간의 **30~40%를 반복 작업**에 쓰고 있습니다.
RTB AI Hub는 이 반복 작업을 AI가 대신 처리하여, 개발자가 진짜 중요한 일에 집중할 수 있게 합니다.

---

## 3. 어떻게 동작하나? (비유로 설명)

RTB AI Hub는 **"AI 비서가 상주하는 개발팀 사무실"** 이라고 생각하면 됩니다.

```
                        ┌─────────────────────────────┐
                        │       RTB AI Hub (AI 비서)    │
                        │                             │
  디자이너가             │  "디자인 분석해서            │
  Figma에서  ──────────▶│   Jira 티켓 만들어둘게요"    │──────▶ Jira에 티켓 자동 생성
  디자인 완성            │                             │
                        │                             │
  PM이 Jira에           │  "요구사항 분석해서           │
  티켓 할당  ──────────▶│   코드 초안 만들어둘게요"     │──────▶ GitHub에 PR 자동 생성
                        │                             │
  개발자가              │  "코드 검토해서               │
  PR 올림   ──────────▶│   리뷰 달아둘게요"           │──────▶ GitHub에 리뷰 코멘트
                        │                             │
  코드가               │  "배포 위험도 분석하고         │
  배포됨    ──────────▶│   모니터링 설정해둘게요"      │──────▶ Datadog에 모니터 생성
                        │                             │
  장애 알림            │  "원인 분석해서               │
  발생      ──────────▶│   티켓 만들어둘게요"          │──────▶ Jira에 버그 티켓 생성
                        │                             │
                        └─────────────────────────────┘
```

**핵심 원리:** 사람이 직접 시키는 게 아닙니다. 각 도구(Figma, Jira, GitHub, Datadog)에서 이벤트가 발생하면, AI Hub가 자동으로 감지하고 적절한 작업을 수행합니다.

---

## 4. 5가지 자동화 시나리오

### 시나리오 1: 디자인 → Jira 티켓 자동 생성

**Before (기존 방식)**

1. 디자이너가 Figma에서 디자인을 완성합니다
2. PM이 디자인을 화면 단위로 분석합니다 (1~2시간)
3. PM이 Jira에 Epic을 만들고, 컴포넌트별로 Sub-task를 하나씩 만듭니다 (1~2시간)
4. 개발자와 미팅하여 티켓 내용을 확인합니다 (30분)
5. **총 소요시간: 2~3일** (다른 업무 병행 시)

**After (AI Hub 방식)**

1. 디자이너가 Figma에서 디자인을 완성합니다
2. AI가 자동으로 디자인을 분석합니다
3. AI가 Epic + Sub-task를 Jira에 자동 생성합니다
4. PM은 생성된 티켓을 검토하고 수정만 합니다
5. **총 소요시간: 2~3시간** (대부분 검토 시간)

> **효과: 90% 시간 단축**

---

### 시나리오 2: Jira 티켓 → 코드 초안 자동 생성

**Before (기존 방식)**

1. 개발자가 Jira 티켓을 읽고 요구사항을 파악합니다
2. 보일러플레이트 코드(기본 틀)를 작성합니다
3. 비즈니스 로직을 구현합니다
4. PR을 만들어 리뷰를 요청합니다
5. **보일러플레이트 작성에만 1~2시간 소요**

**After (AI Hub 방식)**

1. PM이 Jira 티켓 상태를 "In Progress"로 변경합니다
2. AI가 요구사항을 분석하고 코드 초안을 생성합니다
3. AI가 자동으로 브랜치 생성 → 코드 커밋 → PR 생성까지 완료합니다
4. 개발자는 AI가 만든 PR을 검토하고, 비즈니스 로직을 보강합니다
5. **보일러플레이트 작성 시간 제거, 핵심 로직에 집중**

> **효과: 반복 코딩 작업 80% 감소**

---

### 시나리오 3: PR 코드 자동 리뷰

**Before (기존 방식)**

1. 개발자가 PR을 올립니다
2. 시니어 개발자가 코드를 한 줄씩 읽습니다 (30분~2시간)
3. 코멘트를 달고 수정을 요청합니다
4. 수정 후 다시 리뷰합니다
5. **리뷰어의 시간: PR당 평균 4시간**

**After (AI Hub 방식)**

1. 개발자가 PR을 올립니다
2. AI가 즉시 코드를 분석합니다 (보안, 성능, 버그, 코드 품질)
3. AI가 라인별로 구체적인 코멘트를 남깁니다
4. 시니어 개발자는 AI 리뷰를 참고하여 빠르게 최종 리뷰합니다
5. **리뷰어의 시간: PR당 30분** (AI가 1차 필터링 완료)

> **효과: 87% 시간 단축, 리뷰 품질 일관성 확보**

---

### 시나리오 4: 배포 후 자동 모니터링

**Before (기존 방식)**

1. 코드가 배포됩니다
2. 개발자가 수동으로 Datadog 대시보드를 확인합니다
3. 이상 징후를 눈으로 확인합니다
4. 문제가 있으면 롤백을 결정합니다

**After (AI Hub 방식)**

1. 코드가 배포됩니다
2. AI가 배포 위험도를 자동 분석합니다
3. AI가 Datadog에 맞춤형 모니터링 알림을 자동 설정합니다
4. 이상 징후 발생 시 자동 알림이 발생합니다

> **효과: 모니터링 누락 방지, 장애 대응 속도 향상**

---

### 시나리오 5: 장애 알림 → Jira 티켓 자동 생성

**Before (기존 방식)**

1. Datadog에서 장애 알림이 옵니다
2. 온콜 담당자가 알림을 확인합니다
3. 로그를 분석하여 원인을 파악합니다 (15~30분)
4. Jira에 버그 티켓을 직접 작성합니다 (15~30분)
5. **총 소요시간: 30분~1시간** (장애 대응과 병행)

**After (AI Hub 방식)**

1. Datadog에서 장애 알림이 옵니다
2. AI가 즉시 로그와 메트릭을 분석합니다
3. AI가 근본 원인을 추정하고 조사 단계를 포함한 Jira 티켓을 자동 생성합니다
4. 온콜 담당자는 AI가 만든 티켓을 참고하여 빠르게 대응합니다
5. **총 소요시간: 5분** (자동 생성 + 확인)

> **효과: 83% 시간 단축, 장애 기록 누락 방지**

---

## 5. 개발 프로세스가 어떻게 바뀌나?

### 기존 개발 프로세스

```
디자인 완성 ──▶ PM이 수동으로 ──▶ 개발자가 ──▶ 시니어가 ──▶ 수동 ──▶ 수동
(Figma)        티켓 생성         코딩 시작     코드 리뷰     배포     모니터링
               (2~3일)          (보일러플레이트  (4시간/PR)
                                 포함)
```

**문제점:**

- 각 단계 사이에 **대기 시간**이 발생합니다
- 반복 작업에 **고급 인력의 시간**이 낭비됩니다
- 사람에 따라 **품질이 들쭉날쭉**합니다
- 장애 기록이 **누락**되기도 합니다

### AI Hub 도입 후 개발 프로세스

```
디자인 완성 ──▶ AI가 자동으로 ──▶ 개발자가 ──▶ AI가 1차 ──▶ 자동 ──▶ AI가 자동
(Figma)        티켓 생성         핵심 로직     코드 리뷰     배포     모니터링 설정
               (즉시)            에 집중       (즉시)               + 장애 시 티켓 생성
                                 시니어는
                                 2차 리뷰만
```

**개선점:**

- 단계 간 **대기 시간 최소화** (AI가 즉시 처리)
- 개발자는 **핵심 가치 창출에 집중**
- AI 리뷰로 **일관된 코드 품질** 유지
- 장애 기록이 **자동으로 빠짐없이** 남음

---

## 6. 역할별 변화

### PM / 기획자

| 항목           | Before                | After                            |
| -------------- | --------------------- | -------------------------------- |
| Jira 티켓 생성 | 직접 하나씩 작성      | AI가 초안 생성, PM은 검토/수정만 |
| 스프린트 계획  | 티켓 작성에 시간 소요 | 전략과 우선순위에 집중           |
| 진행 상황 추적 | 개발자에게 물어봄     | 대시보드에서 실시간 확인         |

### 디자이너

| 항목            | Before              | After                     |
| --------------- | ------------------- | ------------------------- |
| 디자인 핸드오프 | 별도 문서 작성 필요 | Figma 완성 → 자동 분석    |
| 개발 요청       | PM 통해 전달        | AI가 디자인에서 직접 추출 |
| 구현 확인       | 배포 후 수동 확인   | (향후) 자동 비교 가능     |

### 개발자

| 항목               | Before                | After                         |
| ------------------ | --------------------- | ----------------------------- |
| 보일러플레이트     | 직접 작성             | AI가 초안 생성, 검토 후 보강  |
| 코드 리뷰 (리뷰어) | PR당 4시간            | AI 1차 리뷰 후 30분 최종 검토 |
| 코드 리뷰 (작성자) | 리뷰어 대기           | AI가 즉시 1차 피드백          |
| 장애 대응          | 수동 분석 + 티켓 작성 | AI 분석 결과 참고             |

### 팀 리더 / CTO

| 항목         | Before             | After                         |
| ------------ | ------------------ | ----------------------------- |
| 생산성 측정  | 감에 의존          | 대시보드에서 데이터 기반 확인 |
| AI 비용 관리 | 개별 파악 불가     | 워크플로우별 비용 자동 추적   |
| 품질 관리    | 리뷰어 역량에 의존 | AI 리뷰로 최소 품질 보장      |

---

## 7. 수치로 보는 효과 (10인 개발팀 기준 예상)

| 지표                  | Before     | After     | 변화         |
| --------------------- | ---------- | --------- | ------------ |
| Figma → 개발 시작까지 | 2~3일      | 2~3시간   | **90% 단축** |
| PR 리뷰 시간          | PR당 4시간 | PR당 30분 | **87% 단축** |
| 인시던트 → 티켓 생성  | 30분~1시간 | 5분       | **83% 단축** |
| 주간 반복 작업 시간   | 40시간     | 8시간     | **80% 절감** |
| 스프린트 처리량       | 50 SP      | 75 SP     | **50% 증가** |

---

## 8. 프로젝트가 추구하는 방향

### 단기 목표 (현재 → 3개월)

```
"안정적으로 동작하는 자동화 시스템"
```

- 5가지 자동화 시나리오를 실제 프로젝트에 적용
- 대시보드를 통한 워크플로우 모니터링
- AI 비용 추적 및 예산 관리
- 개발/검증/운영 환경 분리 운영

### 중기 목표 (3개월 → 6개월)

```
"팀 전체가 활용하는 AI 개발 플랫폼"
```

- 팀 단위 권한 관리 (누가 어떤 워크플로우를 쓸 수 있는지)
- 커스텀 워크플로우 추가 (팀별 특화 자동화)
- 실시간 알림 (Slack 연동)
- 성과 리포트 자동 생성

### 장기 목표 (6개월 이후) — Phase A+B+C ✅ 구현 완료

```
"AI가 팀의 소통 매니저가 되는 미래" → Phase A+B+C 구현 완료!
```

아래 6개 기능이 구현되어 점진적으로 활성화할 수 있습니다:

- ✅ **역할 인식 정보 전달 (A-1)**: 같은 이벤트도 디자이너/개발자/PM/QA에게 맞춤 요약으로 전달
- ✅ **PR 맥락 자동 첨부 (A-2)**: Jira 요구사항 + Figma 디자인 + CI 결과가 PR에 자동 포함
- ✅ **일일 팀 다이제스트 (A-3)**: 매일 아침 스프린트 현황, PR 상태, 배포 이력을 Slack으로 요약 전송
- ✅ **맥락 자동 연결 (B-1)**: Figma 시안↔Jira 요구사항↔GitHub PR↔프리뷰↔배포 이력이 하나로 연결
- ✅ **스마트 핸드오프 (B-2)**: 업무 전환(디자인→개발→QA→완료) 시 다음 담당자에게 맥락 브리핑 자동 전달
- ✅ **선제적 블로커 감지 (B-3)**: 정체 티켓, 리뷰 지연을 주기적으로 감지하고 알림

**✅ Phase C도 구현 완료!** (총 9개 기능):

- ✅ **PR 영향 분석 (C-1)**: PR diff를 분석하여 영향 모듈, 리스크 레벨, 유사 과거 변경, 권장 리뷰어 자동 제공
- ✅ **기술 의사결정 저널 (C-2)**: PR/Jira 코멘트에서 기술 결정을 자동 감지·기록. 태그 기반 검색, 주간 다이제스트
- ✅ **회의 준비 자동화 (C-3)**: 데일리 스크럼/스프린트 리뷰 준비 자료를 Jira 데이터 기반으로 자동 생성

**다음 단계**:

- 공식 MCP 서버 마이그레이션 (커스텀 → 공식 Jira/GitHub/Figma/Datadog MCP)
- 여러 팀/프로젝트에서 공유하는 AI 플랫폼

> 📖 자세한 내용: [Team AI Coordinator 비전 문서](./VISION_TEAM_AI_COORDINATOR.md)

---

## 9. 자주 묻는 질문

### Q: AI가 개발자를 대체하나요?

**아닙니다.** AI는 반복적인 "허드렛일"을 대신할 뿐, 설계 판단, 비즈니스 로직 구현, 사용자 경험 결정 등 **창의적인 업무는 여전히 사람의 몫**입니다. AI는 개발자의 **어시스턴트**이지, 대체자가 아닙니다.

### Q: AI가 만든 코드를 그대로 쓰나요?

**아닙니다.** AI가 생성한 코드는 항상 **초안(Draft)** 입니다. 개발자가 반드시 검토하고, 필요한 부분을 수정한 후에 최종 코드가 됩니다. AI는 "빈 도화지에서 시작"하는 부담을 줄여줄 뿐입니다.

### Q: AI 리뷰만으로 충분한가요?

**아닙니다.** AI 리뷰는 **1차 필터** 역할을 합니다. 문법 오류, 보안 취약점, 성능 이슈 등을 빠르게 잡아내지만, 비즈니스 로직의 정확성, 아키텍처 적합성 등은 **시니어 개발자의 2차 리뷰**가 필요합니다.

### Q: 비용은 얼마나 드나요?

AI 호출 비용은 워크플로우별로 자동 추적됩니다. 대략적인 건당 비용:

- 디자인 → Jira: 약 $0.05~0.15
- Jira → 코드 생성: 약 $0.05~0.15
- PR 자동 리뷰: 약 $0.03~0.08
- 배포 모니터링: 약 $0.03~0.08
- 장애 → Jira: 약 $0.03~0.08

10인 팀 기준 월 예상 비용: **$50~200** (사용량에 따라 변동)

### Q: 보안은 안전한가요?

- 외부 서비스와의 통신은 **암호화된 서명(HMAC)** 으로 검증합니다
- 사용자 인증은 **Google OAuth** (회사 계정)를 사용합니다
- API 호출은 **Rate Limiting**으로 남용을 방지합니다
- 개발/검증/운영 환경이 **논리적으로 분리**되어 있습니다

### Q: 기존 도구를 바꿔야 하나요?

**아닙니다.** RTB AI Hub는 기존에 사용하는 도구(Figma, Jira, GitHub, Datadog) 위에서 동작합니다. 새로운 도구를 배울 필요 없이, **기존 워크플로우에 AI가 자연스럽게 끼어드는** 형태입니다.

---

## 10. 시스템 구성도 (간략)

```
┌──────────────────────────────────────────────────────────────────┐
│                        RTB AI Hub                                │
│                                                                  │
│  ┌──────────┐    ┌──────────────┐    ┌───────────────────┐      │
│  │ Dashboard │    │   Webhook    │    │  Workflow Engine   │      │
│  │  (웹 UI)  │    │  Listener    │    │  (AI 두뇌)        │      │
│  │          │    │  (신호 수신)  │    │                   │      │
│  │ - 현황판  │    │              │    │ - Figma→Jira      │      │
│  │ - 이력   │    │ Figma ──────▶│───▶│ - Jira→코드       │      │
│  │ - 비용   │    │ Jira  ──────▶│───▶│ - 자동 리뷰       │      │
│  │          │    │ GitHub ─────▶│───▶│ - 배포 모니터     │      │
│  │          │    │ Datadog ────▶│───▶│ - 장애→Jira       │      │
│  └──────────┘    └──────────────┘    └────────┬──────────┘      │
│                                                │                 │
│                                     ┌──────────▼──────────┐     │
│                                     │    AI (Claude)       │     │
│                                     │   + MCP Servers      │     │
│                                     │                      │     │
│                                     │  Jira API 호출       │     │
│                                     │  GitHub API 호출     │     │
│                                     │  Figma API 호출      │     │
│                                     │  Datadog API 호출    │     │
│                                     └──────────────────────┘     │
│                                                                  │
│  ┌──────────┐    ┌──────────┐                                   │
│  │PostgreSQL│    │  Redis   │                                   │
│  │ (DB)     │    │ (큐)     │                                   │
│  └──────────┘    └──────────┘                                   │
└──────────────────────────────────────────────────────────────────┘
```

| 구성 요소            | 역할 (비유)                                       |
| -------------------- | ------------------------------------------------- |
| **Dashboard**        | 관제탑 - 전체 현황을 한눈에 보는 화면             |
| **Webhook Listener** | 접수 창구 - 외부에서 오는 신호를 받는 곳          |
| **Workflow Engine**  | AI의 두뇌 - 받은 신호를 분석하고 작업을 수행      |
| **MCP Servers**      | AI의 손 - Jira/GitHub/Figma/Datadog를 실제로 조작 |
| **PostgreSQL**       | 기억 저장소 - 모든 작업 기록을 보관               |
| **Redis**            | 대기열 - 작업 순서를 관리하는 줄                  |

---

## 11. 도입 시 고려사항

### 단계적 도입 권장

| 단계      | 도입 범위              | 기간 | 위험도                      |
| --------- | ---------------------- | ---- | --------------------------- |
| **1단계** | PR 자동 리뷰만         | 2주  | 낮음 (읽기만 함)            |
| **2단계** | 장애 → Jira 자동 생성  | 2주  | 낮음 (티켓 생성만)          |
| **3단계** | Figma → Jira 자동 생성 | 4주  | 중간 (PM 워크플로우 변경)   |
| **4단계** | Jira → 코드 자동 생성  | 4주  | 중간 (개발 워크플로우 변경) |
| **5단계** | 배포 자동 모니터링     | 2주  | 낮음 (모니터링 보조)        |

### 성공을 위한 조건

1. **경영진의 지원**: AI 도입은 프로세스 변화를 수반하므로 top-down 지원이 필요합니다
2. **개발팀의 신뢰**: AI 결과물을 "검토 후 개선"하는 문화가 정착되어야 합니다
3. **점진적 확대**: 한 번에 모든 것을 바꾸지 않고, 작은 성공을 쌓아가야 합니다
4. **피드백 루프**: AI 결과물의 품질을 지속적으로 평가하고 개선해야 합니다

---

_이 문서는 2025년 기준으로 작성되었으며, 프로젝트 발전에 따라 업데이트됩니다._
_문의: 개발팀에 Slack으로 연락해주세요._
